{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_channels(raw_df: pd.DataFrame, column_data_str: str, labels):\n",
    "    f, ax = plt.subplots(len(column_data_str), 1, figsize=(30, 3 * len(column_data_str)))\n",
    "    f.tight_layout(pad=2)\n",
    "    timeseries_len = raw_df.shape[0]\n",
    "    for index, column_name in enumerate(column_data_str):\n",
    "        ax[index].plot(range(timeseries_len), raw_df[column_name])\n",
    "        ax[index].set_title(f\"channel: {column_name}\", fontsize=20)\n",
    "\n",
    "        height_line = 1\n",
    "        ax[index].fill_between(range(timeseries_len), 0, height_line, where=labels > 0, color='red', alpha=0.2, transform=ax[index].get_xaxis_transform())\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HASC-2011 dataset preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "raw shape: (39397, 4), label shape: (38, 3)\n",
      "Raw activity data\n",
      "          time         x         y         z\n",
      "0  5015.672119  0.115128 -0.988739 -0.090057\n",
      "1  5015.687371  0.110138 -0.986694 -0.086288\n",
      "2  5015.704061  0.116180 -0.991669 -0.091003\n",
      "3  5015.715389  0.112259 -0.989670 -0.091095\n",
      "4  5015.726564  0.114349 -0.989746 -0.097855\n",
      "\n",
      "raw label data\n",
      "      start       end                    label\n",
      "0  5071.934       NaN       move;escalator;B2F\n",
      "1  5098.502  5126.499         escalatorUp;stay\n",
      "2  5126.970       NaN           move;floor;B1F\n",
      "3  5127.665  5143.411  walk;floor;B1F;steps;22\n",
      "4  5147.988       NaN       move;escalator;B1F\n"
     ]
    }
   ],
   "source": [
    "raw_file = './data/hasc-111018-165936-acc.csv'\n",
    "raw_label = './data/hasc-111018-165936-acc.label'\n",
    "\n",
    "raw_df = pd.read_csv(raw_file, header=None)\n",
    "raw_df.columns = ['time', 'x', 'y', 'z']\n",
    "raw_label_df = pd.read_csv(raw_label, skiprows=1, header=None)\n",
    "raw_label_df.columns = ['start', 'end', 'label']\n",
    "print(f'raw shape: {raw_df.shape}, label shape: {raw_label_df.shape}')\n",
    "print('Raw activity data')\n",
    "print(raw_df.head())\n",
    "print('\\nraw label data')\n",
    "print(raw_label_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   index         time         x         y         z\n",
      "0      0  5015.672119  0.115128 -0.988739 -0.090057\n",
      "1      1  5015.687371  0.110138 -0.986694 -0.086288\n",
      "2      2  5015.704061  0.116180 -0.991669 -0.091003\n",
      "3      3  5015.715389  0.112259 -0.989670 -0.091095\n",
      "4      4  5015.726564  0.114349 -0.989746 -0.097855\n"
     ]
    }
   ],
   "source": [
    "# add index column\n",
    "raw_df = raw_df.reset_index()\n",
    "print(raw_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### L2 norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.999485\n",
       "1    0.996565\n",
       "2    1.002590\n",
       "3    1.000174\n",
       "4    1.001124\n",
       "Name: l2_norm, dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_df['l2_norm'] = np.sqrt(np.square(raw_df[['x', 'y', 'z']]).sum(axis=1))\n",
    "raw_df['l2_norm'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_df[['l2_norm']].to_csv('./data/preprocess/hasc_l2_norm.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## create breakpoints index label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_time = raw_df['time'].to_numpy()\n",
    "raw_label_start = raw_label_df['start'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len: 40, value: [3959, 5305, 7812, 10325, 10565, 13084, 14136, 14184, 14411, 14931, 18428, 19901, 21086, 21538, 23834, 24236, 24469, 24818, 24884, 25214, 25597, 25710, 25780, 26510, 27408, 27431, 28116, 28396, 29188, 30016, 30072, 30407, 30769, 30858, 33567, 34033, 34265, 35529, 37511, 37787]\n"
     ]
    }
   ],
   "source": [
    "breakpoints_index = []\n",
    "start_index = 0\n",
    "for i in range(len(raw_time)):\n",
    "    if start_index < len(raw_label_start) and raw_time[i] > raw_label_start[start_index]:\n",
    "        breakpoints_index.append(i)\n",
    "        start_index += 1\n",
    "print(f'len: {len(breakpoints_index)}, value: {breakpoints_index}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save\n",
    "np.savetxt('./data/preprocess/hasc_label_index.txt', breakpoints_index, fmt='%i')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EEG dataset preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\Minh Nhat\\\\Downloads\\\\DCU\\\\Practicum\\\\TIRE-custom'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.abspath('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Minh Nhat\\Downloads\\DCU\\Practicum\\TIRE-custom\\../Data/grasp-and-lift-eeg-detection/train/\n",
      "file data format: subj1_series2_data.csv\n",
      "file events format: subj1_series2_events.csv\n"
     ]
    }
   ],
   "source": [
    "# dirname = os.path.dirname(__file__) # it's not working with ipynb\n",
    "dirname = os.path.abspath('')\n",
    "eeg_training_data_folder = os.path.join(dirname, '../Data/grasp-and-lift-eeg-detection/train/')\n",
    "print(eeg_training_data_folder)\n",
    "\n",
    "file_data_format = 'subj{}_series{}_data.csv'\n",
    "file_events_format = 'subj{}_series{}_events.csv'\n",
    "subject = 1\n",
    "series = 2\n",
    "print(f'file data format: {file_data_format.format(subject, series)}')\n",
    "print(f'file events format: {file_events_format.format(subject, series)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "def create_files_by_template(base_folder: str, template: str, subjects: iter, series: int):\n",
    "    result = []\n",
    "    for subject in subjects:\n",
    "        file_name = template.format(subject, series)\n",
    "        result.append(os.path.join(base_folder, file_name))\n",
    "    return result \n",
    "\n",
    "def concat_files_by_row(files: List[str]):\n",
    "    def read_file_df(f: str):\n",
    "        df = pd.read_csv(f)\n",
    "        return df\n",
    "    frames = [read_file_df(f) for f in files ]\n",
    "    result = pd.concat(frames)\n",
    "    return result \n",
    "\n",
    "# print(f'test create_files_by_template')\n",
    "# list_file_label = create_files_by_template(eeg_training_data_folder, file_events_format, subjects=range(1, 3), series=1)\n",
    "# print(list_file_label)\n",
    "# combine_label_df = concat_files_by_row(list_file_label)\n",
    "# combine_label_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(series: int):\n",
    "    # create database by series. \n",
    "    # training: subject 1-> 8 / validation: 9, 10 / testing: 11, 12\n",
    "    configs = [('training', range(1, 9)), ('validation', range(9, 11)), ('testing', range(11, 13))]\n",
    "\n",
    "    if os.path.exists('./data/eeg_grasp_and_lift/') == False:\n",
    "        os.makedirs('./data/eeg_grasp_and_lift/')\n",
    "        \n",
    "    for config in configs:\n",
    "        print(f'type: {config[0]}')\n",
    "        list_file_data = create_files_by_template(eeg_training_data_folder, file_data_format, subjects=config[1], series=series)\n",
    "        combine_data_df = concat_files_by_row(list_file_data)\n",
    "        combine_data_df.to_csv(f'./data/eeg_grasp_and_lift/dataset{series}_{config[0]}_data.csv', index=False)\n",
    "\n",
    "        list_file_label = create_files_by_template(eeg_training_data_folder, file_events_format, subjects=config[1], series=series)\n",
    "        combine_label_df = concat_files_by_row(list_file_label)\n",
    "        combine_label_df.to_csv(f'./data/eeg_grasp_and_lift/dataset{series}_{config[0]}_label.csv', index=False)\n",
    "\n",
    "# test create dataset 1\n",
    "# create_dataset(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type: training\n",
      "type: validation\n",
      "type: testing\n",
      "type: training\n",
      "type: validation\n",
      "type: testing\n",
      "type: training\n",
      "type: validation\n",
      "type: testing\n",
      "type: training\n",
      "type: validation\n",
      "type: testing\n",
      "type: training\n",
      "type: validation\n",
      "type: testing\n",
      "type: training\n",
      "type: validation\n",
      "type: testing\n"
     ]
    }
   ],
   "source": [
    "for series in range(3, 9):\n",
    "    create_dataset(series)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generated dataset "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Jump mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import simulate \n",
    "import utils\n",
    "\n",
    "utils.setup_random_seed()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For formulation, check the TIRE paper at page 5\n",
    "Target: examine what data circumstances DMD should be chosen over L2 ?\n",
    "- [Done] Case 1: For jumpmean \n",
    "    - 1 real jump mean\n",
    "    - 2 noise channels (still use AutoRegressive but with constant mean and variance). \n",
    "- Case 2: For jumpman\n",
    "    - 1 real jump mean \n",
    "    - 2 noise channels, but use Gausian noise \n",
    "- Case 3: Channels are nearly the same in distribution shape, but different in magnitude \n",
    "    - Case 3.1: 3 channels jump mean \n",
    "    - Case 3.2: 3 channels Gaussian \n",
    "- Case 4: Mean and variance changed \n",
    "    - 1 channel mean \n",
    "    - 1 channel variance \n",
    "    - 1 channels noise "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## case 1 \n",
    "def _generate_jumpingmean_ar_noise(nr_cp=49, delta_t_cp = 100, delta_t_cp_std = 10, window_size=20, channels = 3):\n",
    "    \"\"\"\n",
    "    Generates one instance of a jumping mean time series, together with the corresponding windows and parameters\n",
    "    \"\"\"\n",
    "    mu = np.zeros((nr_cp,))\n",
    "    parameters_jumpingmean = []\n",
    "    for n in range(1,nr_cp):\n",
    "        mu[n] = mu[n-1] + n / 16 #np.random.randn()*np.sqrt(delta_t_cp_std**3)\n",
    "    # print(f'mu: {mu}')\n",
    "    for n in range(nr_cp):\n",
    "        nr = int(delta_t_cp+ np.random.randn()*np.sqrt(delta_t_cp_std))\n",
    "        parameters_jumpingmean.extend(mu[n]*np.ones((nr,)))\n",
    "    \n",
    "    parameters_jumpingmean = np.array([parameters_jumpingmean]).T\n",
    "\n",
    "    \n",
    "    ts_length = len(parameters_jumpingmean)\n",
    "    all_timeseries = []\n",
    "    for channel in range(channels):\n",
    "        timeseries = np.zeros((ts_length))\n",
    "        for i in range(2,ts_length):\n",
    "            if channel == 0:\n",
    "            #print(ar2(timeseries[i-1],timeseries[i-2], 0.6,-0.5, parameters_jumpingmean[i], 1.5))\n",
    "                timeseries[i] = simulate.ar2(timeseries[i-1],timeseries[i-2], 0.6,-0.5, parameters_jumpingmean[i], 1.5)\n",
    "            elif channel == 1:\n",
    "                timeseries[i] = simulate.ar2(timeseries[i-1],timeseries[i-2], 0.9,-0.7, -1, 5.5)\n",
    "            elif channel == 2:\n",
    "                timeseries[i] = simulate.ar2(timeseries[i-1],timeseries[i-2], 0.7,-0.4, -1.5, 2.5)\n",
    "            elif channel == 3:\n",
    "                timeseries[i] = simulate.ar2(timeseries[i-1],timeseries[i-2], 0.1,-0.3, -0.5, 0.5)\n",
    "            elif channel == 4:\n",
    "                timeseries[i] = simulate.ar2(timeseries[i-1],timeseries[i-2], 0.8, 0.4, 1.5, 4.5)\n",
    "            else:\n",
    "                timeseries[i] = simulate.ar2(timeseries[i-1],timeseries[i-2], 0.6,-0.4, 0, 3.5)\n",
    "        \n",
    "        all_timeseries.append(timeseries)\n",
    "    \n",
    "    breakpoints = utils.parameters_to_cps(parameters_jumpingmean, window_size) # len(breakpoints) = len(timeseries) - 2*window_size + 1\n",
    "    full_breakpoints =  np.concatenate([[0] * (window_size - 1), breakpoints , [0] * window_size])\n",
    "\n",
    "    b_index = np.where(full_breakpoints > 0)[0]\n",
    "    full_breakpoints[b_index] = [1] * len(b_index)\n",
    "    \n",
    "    return np.array(all_timeseries), full_breakpoints\n",
    "\n",
    "def generate_jumpingmean_ar_no_noise(nr_cp=49, delta_t_cp = 100, delta_t_cp_std = 10, window_size=20, channels = 1):\n",
    "    return _generate_jumpingmean_ar_noise(nr_cp, delta_t_cp, delta_t_cp_std, window_size, channels)\n",
    "\n",
    "def generate_jumpingmean_ar_1_noise(nr_cp=49, delta_t_cp = 100, delta_t_cp_std = 10, window_size=20, channels = 2):\n",
    "    return _generate_jumpingmean_ar_noise(nr_cp, delta_t_cp, delta_t_cp_std, window_size, channels)\n",
    "\n",
    "def generate_jumpingmean_ar_2_noise(nr_cp=49, delta_t_cp = 100, delta_t_cp_std = 10, window_size=20, channels = 3):\n",
    "    return _generate_jumpingmean_ar_noise(nr_cp, delta_t_cp, delta_t_cp_std, window_size, channels)\n",
    "\n",
    "def generate_jumpingmean_ar_3_noise(nr_cp=49, delta_t_cp = 100, delta_t_cp_std = 10, window_size=20, channels = 4):\n",
    "    return _generate_jumpingmean_ar_noise(nr_cp, delta_t_cp, delta_t_cp_std, window_size, channels)\n",
    "\n",
    "def generate_jumpingmean_ar_4_noise(nr_cp=49, delta_t_cp = 100, delta_t_cp_std = 10, window_size=20, channels = 5):\n",
    "    return _generate_jumpingmean_ar_noise(nr_cp, delta_t_cp, delta_t_cp_std, window_size, channels)\n",
    "\n",
    "def generate_jumpingmean_ar_5_noise(nr_cp=49, delta_t_cp = 100, delta_t_cp_std = 10, window_size=20, channels = 6):\n",
    "    return _generate_jumpingmean_ar_noise(nr_cp, delta_t_cp, delta_t_cp_std, window_size, channels)\n",
    "### case 2 \n",
    "def _generate_gaussian_noise(nr_cp=49, delta_t_cp = 100, delta_t_cp_std = 10, window_size=20, channels = 1):\n",
    "    \"\"\"\n",
    "    Generates one instance of a jumping mean time series, together with the corresponding windows and parameters\n",
    "    \"\"\"\n",
    "    mixturenumber = np.zeros((nr_cp,))\n",
    "    parameters_gaussian = []\n",
    "    for n in range(1,nr_cp-1,2):\n",
    "        mixturenumber[n] = 1\n",
    "    for n in range(nr_cp):\n",
    "        nr = int(delta_t_cp+np.random.randn()*np.sqrt(delta_t_cp_std))\n",
    "        parameters_gaussian.extend(mixturenumber[n]*np.ones((nr,)))\n",
    "\n",
    "    parameters_gaussian = np.array([parameters_gaussian]).T\n",
    "\n",
    "\n",
    "    ts_length = len(parameters_gaussian)\n",
    "    all_timeseries = []\n",
    "    for channel in range(channels):\n",
    "        timeseries = np.zeros((ts_length))\n",
    "        for i in range(2,ts_length):\n",
    "            if channel == 0:\n",
    "                if parameters_gaussian[i] == 0:\n",
    "                    timeseries[i] = 0.5*0.5*np.random.randn()+0.5*0.5*np.random.randn()\n",
    "                else:\n",
    "                    timeseries[i] = -0.6 - 0.8*1*np.random.randn() + 0.2*0.1*np.random.randn()\n",
    "            elif channel == 1:\n",
    "                timeseries[i] = np.random.normal(-1, 5.5)\n",
    "            elif channel == 2:\n",
    "                timeseries[i] = np.random.normal(0, 3.5)\n",
    "            elif channel == 3: \n",
    "                timeseries[i] = np.random.normal(-2, 2)\n",
    "            elif channel == 4:\n",
    "                timeseries[i] = np.random.normal(3, 1)\n",
    "            else:\n",
    "                timeseries[i] = np.random.normal(0, 3)\n",
    "        \n",
    "        all_timeseries.append(timeseries)\n",
    "    \n",
    "    breakpoints = utils.parameters_to_cps(parameters_gaussian, window_size) # len(breakpoints) = len(timeseries) - 2*window_size + 1\n",
    "    full_breakpoints =  np.concatenate([[0] * (window_size - 1), breakpoints , [0] * window_size])\n",
    "\n",
    "    b_index = np.where(full_breakpoints > 0)[0]\n",
    "    full_breakpoints[b_index] = [1] * len(b_index)\n",
    "    \n",
    "    return np.array(all_timeseries), full_breakpoints\n",
    "\n",
    "def generate_gaussian_no_noise(nr_cp=49, delta_t_cp = 100, delta_t_cp_std = 10, window_size=20, channels = 1):\n",
    "    return _generate_gaussian_noise(nr_cp, delta_t_cp, delta_t_cp_std, window_size, channels)    \n",
    "\n",
    "def generate_gaussian_1_noise(nr_cp=49, delta_t_cp = 100, delta_t_cp_std = 10, window_size=20, channels = 2):\n",
    "    return _generate_gaussian_noise(nr_cp, delta_t_cp, delta_t_cp_std, window_size, channels) \n",
    "\n",
    "def generate_gaussian_2_noise(nr_cp=49, delta_t_cp = 100, delta_t_cp_std = 10, window_size=20, channels = 3):\n",
    "    return _generate_gaussian_noise(nr_cp, delta_t_cp, delta_t_cp_std, window_size, channels)  \n",
    "\n",
    "def generate_gaussian_3_noise(nr_cp=49, delta_t_cp = 100, delta_t_cp_std = 10, window_size=20, channels = 4):\n",
    "    return _generate_gaussian_noise(nr_cp, delta_t_cp, delta_t_cp_std, window_size, channels) \n",
    "\n",
    "def generate_gaussian_4_noise(nr_cp=49, delta_t_cp = 100, delta_t_cp_std = 10, window_size=20, channels = 5):\n",
    "    return _generate_gaussian_noise(nr_cp, delta_t_cp, delta_t_cp_std, window_size, channels) \n",
    "\n",
    "def generate_gaussian_5_noise(nr_cp=49, delta_t_cp = 100, delta_t_cp_std = 10, window_size=20, channels = 6):\n",
    "    return _generate_gaussian_noise(nr_cp, delta_t_cp, delta_t_cp_std, window_size, channels) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Case 3: Channels are nearly the same in distribution shape, but different in magnitude \n",
    "# Case 3.1: 3 channels jump mean \n",
    "def generate_jumpingmean_diff_magnitude(nr_cp=49, delta_t_cp = 100, delta_t_cp_std = 10, window_size=20):\n",
    "    \"\"\"\n",
    "    Generates one instance of a jumping mean time series, together with the corresponding windows and parameters\n",
    "    \"\"\"\n",
    "    mu = np.zeros((nr_cp,))\n",
    "    parameters_jumpingmean = []\n",
    "    for n in range(1,nr_cp):\n",
    "        mu[n] = mu[n-1] + n / 16 #np.random.randn()*np.sqrt(delta_t_cp_std**3)\n",
    "    # print(f'mu: {mu}')\n",
    "    for n in range(nr_cp):\n",
    "        nr = int(delta_t_cp+ np.random.randn()*np.sqrt(delta_t_cp_std))\n",
    "        parameters_jumpingmean.extend(mu[n]*np.ones((nr,)))\n",
    "    \n",
    "    parameters_jumpingmean = np.array([parameters_jumpingmean]).T\n",
    "\n",
    "    channels = 3\n",
    "    ts_length = len(parameters_jumpingmean)\n",
    "    all_timeseries = []\n",
    "    for channel in range(channels):\n",
    "        timeseries = np.zeros((ts_length))\n",
    "        for i in range(2,ts_length):\n",
    "            if channel == 0:\n",
    "            #print(ar2(timeseries[i-1],timeseries[i-2], 0.6,-0.5, parameters_jumpingmean[i], 1.5))\n",
    "                timeseries[i] = simulate.ar2(timeseries[i-1],timeseries[i-2], 0.6,-0.5, parameters_jumpingmean[i], 1.5)\n",
    "            elif channel == 1:\n",
    "                timeseries[i] = simulate.ar2(timeseries[i-1],timeseries[i-2], 0.9,-0.7, parameters_jumpingmean[i] + 2, 5.5)\n",
    "            else:\n",
    "                timeseries[i] = simulate.ar2(timeseries[i-1],timeseries[i-2], 0.8,-0.1, parameters_jumpingmean[i] - 5, 3.5)\n",
    "        \n",
    "        all_timeseries.append(timeseries)\n",
    "    \n",
    "    breakpoints = utils.parameters_to_cps(parameters_jumpingmean, window_size) # len(breakpoints) = len(timeseries) - 2*window_size + 1\n",
    "    full_breakpoints =  np.concatenate([[0] * (window_size - 1), breakpoints , [0] * window_size])\n",
    "\n",
    "    b_index = np.where(full_breakpoints > 0)[0]\n",
    "    full_breakpoints[b_index] = [1] * len(b_index)\n",
    "    \n",
    "    return np.array(all_timeseries), full_breakpoints\n",
    "\n",
    "# Case 3.2: 3 channels gauss \n",
    "def generate_gauss_diff_magnitude(window_size, stride=1, nr_cp=49, delta_t_cp = 100, delta_t_cp_std = 10, scale_min=-1, scale_max=1):\n",
    "    \"\"\"\n",
    "    Generates one instance of a Gaussian mixtures time series, together with the corresponding windows and parameters\n",
    "    \"\"\"\n",
    "    mixturenumber = np.zeros((nr_cp,))\n",
    "    parameters_gaussian = []\n",
    "    for n in range(1,nr_cp-1,2):\n",
    "        mixturenumber[n] = 1\n",
    "    for n in range(nr_cp):\n",
    "        nr = int(delta_t_cp+np.random.randn()*np.sqrt(delta_t_cp_std))\n",
    "        parameters_gaussian.extend(mixturenumber[n]*np.ones((nr,)))\n",
    "\n",
    "    parameters_gaussian = np.array([parameters_gaussian]).T\n",
    "\n",
    "    ts_length = len(parameters_gaussian)\n",
    "    \n",
    "    channels = 3\n",
    "    all_timeseries = []\n",
    "\n",
    "    for channel in range(channels):\n",
    "        timeseries = np.zeros((ts_length))\n",
    "        if channel == 0:\n",
    "            for i in range(2,ts_length):\n",
    "                if parameters_gaussian[i] == 0:\n",
    "                    timeseries[i] = 0.5*0.5*np.random.randn()+0.5*0.5*np.random.randn()\n",
    "                else:\n",
    "                    timeseries[i] = -0.6 - 0.8*1*np.random.randn() + 0.2*0.1*np.random.randn()\n",
    "        \n",
    "        elif channel == 1:\n",
    "            for i in range(2,ts_length):\n",
    "                if parameters_gaussian[i] == 0:\n",
    "                    timeseries[i] = 0.5*0.5*np.random.randn()+0.5*0.5*np.random.randn()\n",
    "                else:\n",
    "                    timeseries[i] = -0.6 - 0.8*1*np.random.randn() + 0.2*0.1*np.random.randn()\n",
    "        elif channel == 2: \n",
    "            for i in range(2,ts_length):\n",
    "                if parameters_gaussian[i] == 0:\n",
    "                    timeseries[i] = 0.5*0.5*np.random.randn()+0.5*0.5*np.random.randn()\n",
    "                else:\n",
    "                    timeseries[i] = -0.6 - 0.8*1*np.random.randn() + 0.2*0.1*np.random.randn()\n",
    "        \n",
    "        all_timeseries.append(timeseries)\n",
    "        \n",
    "\n",
    "    breakpoints = utils.parameters_to_cps(parameters_gaussian, window_size) # len(breakpoints) = len(timeseries) - 2*window_size + 1\n",
    "    full_breakpoints =  np.concatenate([[0] * (window_size - 1), breakpoints , [0] * window_size])\n",
    "\n",
    "    b_index = np.where(full_breakpoints > 0)[0]\n",
    "    full_breakpoints[b_index] = [1] * len(b_index)\n",
    "    return np.array(all_timeseries), full_breakpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## case 4\n",
    "def _generate_jumpingmean_variance_noise(nr_cp=49, delta_t_cp = 100, delta_t_cp_std = 10, window_size=20, channels = 3):\n",
    "    \"\"\"\n",
    "    Generates one instance of a jumping mean time series, together with the corresponding windows and parameters\n",
    "    \"\"\"\n",
    "    # for jumpmean\n",
    "    mu = np.zeros((nr_cp,))\n",
    "    parameters_jumpingmean = []\n",
    "    for n in range(1,nr_cp):\n",
    "        mu[n] = mu[n-1] + n / 16 #np.random.randn()*np.sqrt(delta_t_cp_std**3)\n",
    "    \n",
    "    # for variance\n",
    "    sigma = np.ones((nr_cp,))\n",
    "    parameters_scalingvariance = []\n",
    "    for n in range(1,nr_cp-1,2):\n",
    "        sigma[n] = np.log(np.exp(1)+n/4)      \n",
    "\n",
    "    for n in range(nr_cp):\n",
    "        nr = int(delta_t_cp+ np.random.randn()*np.sqrt(delta_t_cp_std))\n",
    "        parameters_jumpingmean.extend(mu[n]*np.ones((nr,)))\n",
    "        parameters_scalingvariance.extend(sigma[n]*np.ones((nr,)))\n",
    "    \n",
    "    \n",
    "    parameters_jumpingmean = np.array([parameters_jumpingmean]).T\n",
    "    parameters_scalingvariance = np.array([parameters_scalingvariance]).T\n",
    "\n",
    "    \n",
    "    ts_length = len(parameters_jumpingmean)\n",
    "    all_timeseries = []\n",
    "    for channel in range(channels):\n",
    "        timeseries = np.zeros((ts_length))\n",
    "        for i in range(2,ts_length):\n",
    "            # channel 0: jumpmean\n",
    "            if channel == 0:\n",
    "            #print(ar2(timeseries[i-1],timeseries[i-2], 0.6,-0.5, parameters_jumpingmean[i], 1.5))\n",
    "                timeseries[i] = simulate.ar2(timeseries[i-1],timeseries[i-2], 0.6,-0.5, parameters_jumpingmean[i], 1.5)\n",
    "            # channel 1: gauss\n",
    "            elif channel == 1:\n",
    "                timeseries[i] = simulate.ar2(timeseries[i-1],timeseries[i-2], 0.6,-0.5, 0, parameters_scalingvariance[i])\n",
    "            # channel 3: noise: arr\n",
    "            else:\n",
    "                timeseries[i] = simulate.ar2(timeseries[i-1],timeseries[i-2], 0.6,-0.4, 0, 3.5)\n",
    "        \n",
    "        all_timeseries.append(timeseries)\n",
    "    \n",
    "    breakpoints = utils.parameters_to_cps(parameters_jumpingmean, window_size) # len(breakpoints) = len(timeseries) - 2*window_size + 1\n",
    "    full_breakpoints =  np.concatenate([[0] * (window_size - 1), breakpoints , [0] * window_size])\n",
    "\n",
    "    b_index = np.where(full_breakpoints > 0)[0]\n",
    "    full_breakpoints[b_index] = [1] * len(b_index)\n",
    "    \n",
    "    return np.array(all_timeseries), full_breakpoints\n",
    "\n",
    "def generate_jumpingmean_variance_noise(nr_cp=49, delta_t_cp = 100, delta_t_cp_std = 10, window_size=20, channels = 3):\n",
    "    return _generate_jumpingmean_variance_noise(nr_cp, delta_t_cp, delta_t_cp_std, window_size, channels)\n",
    "\n",
    "def generate_jumpingmean_variance_2_noise(nr_cp=49, delta_t_cp = 100, delta_t_cp_std = 10, window_size=20, channels = 4):\n",
    "    return _generate_jumpingmean_variance_noise(nr_cp, delta_t_cp, delta_t_cp_std, window_size, channels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def saving_single_generate_dataset(timeseries, breakpoints, dataset_number: int, datatype: str, folder_prefix: str):\n",
    "    utils.create_folder_if_not_exist(f'./data-gen/{folder_prefix}')\n",
    "\n",
    "    timeseries_df = pd.DataFrame(timeseries.T)\n",
    "    timeseries_df.columns = [f'col_{col}' for col in timeseries_df.columns]\n",
    "    timeseries_df.to_csv(f'./data-gen/{folder_prefix}/{folder_prefix}-dataset{dataset_number}-{datatype}-data.csv', index=False)\n",
    "    \n",
    "\n",
    "    breakpoints_df = pd.DataFrame(breakpoints)\n",
    "    breakpoints_df.columns = [f'col_{col}' for col in breakpoints_df.columns]\n",
    "    breakpoints_df.to_csv(f'./data-gen/{folder_prefix}/{folder_prefix}-dataset{dataset_number}-{datatype}-label.csv', index=False)\n",
    "\n",
    "'''\n",
    "generated_type:\n",
    "case 1: jumpmean_ar\n",
    "case 1.1: jumpmean_ar_1_noise\n",
    "case 2: jumpmean_gauss\n",
    "case 3.1: jumpmean_diff_magnitude\n",
    "case 3.2: gauss_diff_magnitude\n",
    "case 4: jumpmean_scalevariance\n",
    "'''\n",
    "def saving_generate_datasets(generated_type: str):\n",
    "    if generated_type == 'jumpmean_ar_no_noise':\n",
    "        generate_dataset_f = generate_jumpingmean_ar_no_noise\n",
    "    elif generated_type == 'jumpmean_ar_1_noise':\n",
    "        generate_dataset_f = generate_jumpingmean_ar_1_noise\n",
    "    elif generated_type == 'jumpmean_ar_2_noise':\n",
    "        generate_dataset_f = generate_jumpingmean_ar_2_noise\n",
    "    elif generated_type == 'jumpmean_ar_3_noise':\n",
    "        generate_dataset_f = generate_jumpingmean_ar_3_noise\n",
    "    elif generated_type == 'jumpmean_ar_4_noise':\n",
    "        generate_dataset_f = generate_jumpingmean_ar_4_noise\n",
    "    elif generated_type == 'jumpmean_ar_5_noise':\n",
    "        generate_dataset_f = generate_jumpingmean_ar_5_noise\n",
    "    # gaussian with noise \n",
    "    elif generated_type == 'gauss-no-noise':\n",
    "        generate_dataset_f = generate_gaussian_no_noise\n",
    "    elif generated_type == 'gauss-1-noise':\n",
    "        generate_dataset_f = generate_gaussian_1_noise\n",
    "    elif generated_type == 'gauss-2-noise':\n",
    "        generate_dataset_f = generate_gaussian_2_noise\n",
    "    elif generated_type == 'gauss-3-noise':\n",
    "        generate_dataset_f = generate_gaussian_3_noise\n",
    "    elif generated_type == 'gauss-4-noise':\n",
    "        generate_dataset_f = generate_gaussian_4_noise\n",
    "    elif generated_type == 'gauss-5-noise':\n",
    "        generate_dataset_f = generate_gaussian_5_noise\n",
    "    # for same distribution but different in magnitude \n",
    "    elif generated_type == 'jumpmean_diff_magnitude': \n",
    "        generate_dataset_f = generate_jumpingmean_diff_magnitude\n",
    "    elif generated_type == 'gauss_diff_magnitude':\n",
    "        generate_dataset_f = generate_gauss_diff_magnitude\n",
    "    elif generated_type == 'jumpmean_scalevariance':\n",
    "        generate_dataset_f = generate_jumpingmean_variance_noise\n",
    "    elif generated_type == 'jumpmean_scalevariance_2_noise':\n",
    "        generate_dataset_f = generate_jumpingmean_variance_2_noise\n",
    "    else:\n",
    "        print('Please check generated_type parameter')\n",
    "        return \n",
    "\n",
    "    folder_prefix = generated_type.replace('_', '-')    \n",
    "    for dataset_number in range(1, 11):\n",
    "        for t in [('training', 49), ('validation', 49), ('testing', 49)]:\n",
    "\n",
    "            timeseries, breakpoints = generate_dataset_f(nr_cp = t[1], window_size=20) # 20 for jump mean\n",
    "            saving_single_generate_dataset(timeseries, breakpoints, dataset_number, t[0], folder_prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.setup_random_seed()\n",
    "saving_generate_datasets('gauss-5-noise')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../data-gen/jumpmean-gauss/jumpmean-gauss-dataset1-training-data.csv'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "folder_prefix = '../data-gen/jumpmean-gauss/jumpmean-gauss'\n",
    "dataset_number = 1 \n",
    "f'{folder_prefix}-dataset{dataset_number}-training-data.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'gauss-no-noise'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = 'gauss_no_noise'\n",
    "a.replace('_', '-')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## do some stats for EEG \n",
    "calcualte lenght, change point number of trainig/validation/testing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import count\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "import experiments.utils_eeg as utils_eeg\n",
    "import os \n",
    "\n",
    "folder_path = \"./data/eeg_grasp_and_lift\"\n",
    "data_format = \"dataset{}_{}_data.csv\"\n",
    "label_format = \"dataset{}_{}_label.csv\"\n",
    "\n",
    "def loop_through_dataset_type(ds_type: str):\n",
    "    data_length = []\n",
    "    number_cp = []\n",
    "    for i in range(1, 9):\n",
    "        print(f'doing ds: {i}')\n",
    "        data_path = os.path.join(folder_path, data_format.format(i, ds_type))\n",
    "        label_path = os.path.join(folder_path, label_format.format(i, ds_type))\n",
    "    \n",
    "        data_df = pd.read_csv(data_path)\n",
    "        data_length.append(data_df.shape[0])\n",
    "\n",
    "        labels_df = pd.read_csv(label_path) # , 'FirstDigitTouch', 'LiftOff', 'BothReleased'\n",
    "        labels_df.drop(['id'], axis=1, inplace=True)\n",
    "\n",
    "        result = utils_eeg.create_break_point_index(labels_df=labels_df)\n",
    "        count_cp = len(np.where(result > 0)[0])\n",
    "        number_cp.append(count_cp)\n",
    "    \n",
    "    print(f'data_lenght: {data_length}, mean: {np.mean(data_length)}, std: {np.std(data_length)}, min: {np.min(data_length)}, max: {np.max(data_length)}')\n",
    "    print(f'number_cp: {number_cp}, mean: {np.mean(number_cp)}, std: {np.std(number_cp)}, min: {np.min(number_cp)}, max: {np.max(number_cp)}')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doing ds: 1\n",
      "doing ds: 2\n",
      "doing ds: 3\n",
      "doing ds: 4\n",
      "doing ds: 5\n",
      "doing ds: 6\n",
      "doing ds: 7\n",
      "doing ds: 8\n",
      "data_lenght: [374523, 417744, 497117, 297681, 481356, 482554, 289018, 288967], mean: 391120.0, std: 85376.57347012704, min: 288967, max: 497117\n",
      "number_cp: [525, 585, 549, 543, 501, 527, 541, 549], mean: 540.0, std: 22.67156809750927, min: 501, max: 585\n"
     ]
    }
   ],
   "source": [
    "loop_through_dataset_type('testing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doing ds: 1\n",
      "doing ds: 2\n",
      "doing ds: 3\n",
      "doing ds: 4\n",
      "doing ds: 5\n",
      "doing ds: 6\n",
      "doing ds: 7\n",
      "doing ds: 8\n",
      "data_lenght: [403813, 426085, 395748, 419695, 384869, 388943, 261029, 254227], mean: 366801.125, std: 64418.09440374168, min: 254227, max: 426085\n",
      "number_cp: [587, 471, 567, 455, 557, 595, 545, 501], mean: 534.75, std: 49.45136499632745, min: 455, max: 595\n"
     ]
    }
   ],
   "source": [
    "loop_through_dataset_type('validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doing ds: 1\n",
      "doing ds: 2\n",
      "doing ds: 3\n",
      "doing ds: 4\n",
      "doing ds: 5\n",
      "doing ds: 6\n",
      "doing ds: 7\n",
      "doing ds: 8\n",
      "data_lenght: [1665853, 1861494, 1559664, 1576806, 1546503, 1638899, 1039162, 1034004], mean: 1490298.125, std: 277909.71299571265, min: 1034004, max: 1861494\n",
      "number_cp: [2001, 2045, 1905, 2007, 1835, 1819, 1965, 1959], mean: 1942.0, std: 76.71375365604267, min: 1819, max: 2045\n"
     ]
    }
   ],
   "source": [
    "loop_through_dataset_type('training')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b1e259f8989b5c9c45559a1752ef2f72f727f33e7b4cd49fa4d8dfdfbce9ad9e"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('ml')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
